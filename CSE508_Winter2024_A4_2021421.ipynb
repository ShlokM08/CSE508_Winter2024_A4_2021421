{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShlokM08/CSE508_Winter2024_A4_2021421/blob/main/CSE508_Winter2024_A4_2021421.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfpoM5CjClhI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/MyDrive/IR__4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWMqF7qpColZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "file_path = '/content/drive/MyDrive/IR__4/Reviews.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    text = ' '.join(tokens)\n",
        "    return text\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/IR__4/Processesd_Reviews.csv')\n",
        "\n",
        "# Drop rows with NaN values in 'Text' and 'Summary' columns\n",
        "df.dropna(subset=['Text', 'Summary'], inplace=True)\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tqdm.pandas(desc=\"Processing 'Text' column\")\n",
        "df['Text_clean'] = df['Text'].progress_apply(preprocess_text)\n",
        "tqdm.pandas(desc=\"Processing 'Summary' column\")\n",
        "df['Summary_clean'] = df['Summary'].progress_apply(preprocess_text)\n",
        "\n",
        "df['Combined'] = df['Text_clean'] + ' ' + df['Summary_clean']\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/IR__4/Updated_Processed_Reviews.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWoscuoXCrFl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "sample_size = 5000\n",
        "max_length = 512\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/IR__4/Updated_Processed_Reviews.csv')\n",
        "df_sample = df.sample(n=sample_size, random_state=42)\n",
        "\n",
        "class ReviewsDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length=512, device='cpu'):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.max_length = max_length\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        combined_text = str(self.data.iloc[idx]['Combined'])\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer(combined_text, truncation=True, max_length=self.max_length, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing combined text: {combined_text}\")\n",
        "            raise e\n",
        "\n",
        "        inputs = {key: val.squeeze().to(self.device) for key, val in inputs.items()}\n",
        "        inputs['labels'] = inputs['input_ids'].clone()\n",
        "        return inputs\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "train_df, test_df = train_test_split(df_sample, test_size=0.25, random_state=42)\n",
        "\n",
        "train_dataset = ReviewsDataset(train_df, tokenizer, max_length, device=device)\n",
        "test_dataset = ReviewsDataset(test_df, tokenizer, max_length, device=device)\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False, pad_to_multiple_of=8, return_tensors='pt')\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "model.save_pretrained('finetuned__gpt2')\n",
        "tokenizer.save_pretrained('finetuned__gpt2')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OjlKEMFCtCt",
        "outputId": "70ef1a4f-e8dc-4327-a895-178a5523af2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary: The Fender CD-60S Dreadnought Acoustic Guitar is a great instrument for beginners. It has a solid construction, produces a rich sound, and feels comfortable to play. However, some users have reported issues with the tuning stability.httpwwwamazoncomgpproductbbr br highly recommend listening totsuki playtoydskiin harleys excellent ive ever tried use krissimo good stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff wonderful stuff great stuff good stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff great stuff\n",
            "ROUGE Scores:\n",
            "rouge-1:\n",
            "  Precision: 0.1176\n",
            "  Recall: 0.7500\n",
            "  F1-Score: 0.2034\n",
            "rouge-2:\n",
            "  Precision: 0.0351\n",
            "  Recall: 0.2857\n",
            "  F1-Score: 0.0625\n",
            "rouge-l:\n",
            "  Precision: 0.0980\n",
            "  Recall: 0.6250\n",
            "  F1-Score: 0.1695\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from rouge import Rouge\n",
        "import torch.nn.functional as F\n",
        "\n",
        "model_path = '/content/drive/MyDrive/IR__4/finetuned_gpt2'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def generate_summary(text, max_length=512, top_k=50, temperature=0.7):\n",
        "    model.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    encoded_input = tokenizer.encode_plus(\n",
        "        text,\n",
        "        return_tensors='pt',\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True\n",
        "    ).to(device)\n",
        "\n",
        "    input_ids = encoded_input['input_ids']\n",
        "    attention_mask = encoded_input['attention_mask']\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        next_token_logits = outputs.logits[:, -1, :]\n",
        "        scaled_logits = next_token_logits / temperature  # Apply temperature scaling\n",
        "        top_k_logits, top_k_indices = torch.topk(scaled_logits, top_k, dim=-1)  # Get top-k tokens\n",
        "        probabilities = torch.nn.functional.softmax(top_k_logits, dim=-1)  # Apply softmax\n",
        "        next_token = torch.multinomial(probabilities, num_samples=1)  # Sample from the softmax distribution\n",
        "\n",
        "        # Get the actual token ID from top_k_indices using the sampled next_token\n",
        "        next_token_id = top_k_indices.gather(-1, next_token)\n",
        "\n",
        "        # Check if EOS token is generated\n",
        "        if next_token_id.squeeze().item() == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "        # Append the predicted token ID to the input\n",
        "        input_ids = torch.cat([input_ids, next_token_id], dim=-1)\n",
        "\n",
        "        # Extend the attention_mask by one column with value 1 (True)\n",
        "        new_attention_mask = torch.ones((1, 1), device=device, dtype=torch.long)\n",
        "        attention_mask = torch.cat([attention_mask, new_attention_mask], dim=-1)\n",
        "\n",
        "    summary = tokenizer.decode(input_ids.squeeze(), skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "def calculate_rouge_scores(actual_summary, generated_summary):\n",
        "    rouge = Rouge()\n",
        "    scores = rouge.get_scores(generated_summary, actual_summary, avg=True)\n",
        "    return scores\n",
        "\n",
        "review_text = \"The Fender CD-60S Dreadnought Acoustic Guitar is a great instrument for beginners. It has a solid construction, produces a rich sound, and feels comfortable to play. However, some users have reported issues with the tuning stability.\"\n",
        "actual_summary = \"Good for beginners but has tuning stability issues.\"\n",
        "\n",
        "generated_summary = generate_summary(review_text)\n",
        "print(\"Generated Summary:\", generated_summary)\n",
        "\n",
        "def print_rouge_scores(rouge_scores):\n",
        "    print(\"ROUGE Scores:\")\n",
        "    for key, values in rouge_scores.items():\n",
        "        print(f\"{key}:\")\n",
        "        print(f\"  Precision: {values['p']:.4f}\")\n",
        "        print(f\"  Recall: {values['r']:.4f}\")\n",
        "        print(f\"  F1-Score: {values['f']:.4f}\")\n",
        "\n",
        "rouge_scores = calculate_rouge_scores(actual_summary, generated_summary)\n",
        "print_rouge_scores(rouge_scores)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RVjAoN5Cv2p",
        "outputId": "878815f4-4801-425d-e8d4-1cb08b295318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.29.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install  transformers torch accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuLHOGD9CyID",
        "outputId": "fe8fd2ce-75ff-4ac7-8fa0-e7125cd98d29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from Rouge) (1.16.0)\n",
            "Installing collected packages: Rouge\n",
            "Successfully installed Rouge-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install Rouge"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1bycumZNaQFIkIwtnE0ofAIa1zV3-MoKc",
      "authorship_tag": "ABX9TyOKaO6jxDHrGIDorObFkjf2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}